{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd2aa45",
   "metadata": {},
   "source": [
    "# Pre-requisites - IMPORTANT!!!\n",
    "\n",
    "In order to run properly this notebook, you need to:\n",
    "\n",
    "1. Have a `.env` at the root of your project (You can use `.env.example` with the values on it)\n",
    "2. Run `export PYTHONPATH=$PWD` in the root of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b221da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681ecbf",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9af92",
   "metadata": {},
   "source": [
    "These functions are also in the conabio module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41e97e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_alfresco(api_key):\n",
    "    import requests\n",
    "    \"\"\"\n",
    "    Creates a session in Alfresco\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api_key : string\n",
    "        Api key that can come from the .env credentials\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    session : requests.Session\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session = requests.Session()\n",
    "        session.headers.update({'x-api-key': api_key})\n",
    "\n",
    "        return session\n",
    "    except Exception as e:\n",
    "        print(\"Login failed: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ed54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(dictionary, file_path_name, overwrite=True):\n",
    "    \"\"\"\n",
    "    Save a dictionary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "    \n",
    "    file_path_name : string\n",
    "        Complete file path with the name of the file\n",
    "    \n",
    "    overwrite : boolean\n",
    "        Default is True\n",
    "    \"\"\"\n",
    "    # Serializing json\n",
    "    json_object = json.dumps(dictionary, indent=4)\n",
    "\n",
    "    outcome = \"w\"\n",
    "\n",
    "    if not overwrite:\n",
    "        outcome = \"w+\"\n",
    "\n",
    "    # Writing to sample.json\n",
    "    with open(f\"{file_path_name}\", outcome) as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3421f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    f = open(path)\n",
    "    json_file = json.load(f)\n",
    "\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list_as_csv(path, header, list_path, overwrite=True):\n",
    "    import csv\n",
    "    write_mode = \"w\"\n",
    "    if not overwrite:\n",
    "        write_mode = \"w+\"\n",
    "\n",
    "    with open(path, write_mode) as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(header)\n",
    "        write.writerows(list_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2d75e",
   "metadata": {},
   "source": [
    "### Load the environment set at the root (.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d54d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CONFIG = dotenv_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e4603",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913a5fe",
   "metadata": {},
   "source": [
    "- The cumulus you want to extract videos from\n",
    "\n",
    "- Date intervals you want the videos from \n",
    "\n",
    "- The output path were the results are going to be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3713eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUMULUS = 92\n",
    "MIN_DATE = \"2021-11-01\" \n",
    "MAX_DATE = \"2021-12-01\" \n",
    "\n",
    "OUTPUT_PATH = \"../../../results/search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d63d2",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93f39bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITEMS = 5000\n",
    "FILE_TYPE = \"Video\"\n",
    "BUCKET_NAME = \"sipecam-open-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352b1ec",
   "metadata": {},
   "source": [
    "### Create your query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fc6a3",
   "metadata": {},
   "source": [
    "In this query we want to search for the video in the cumulus 92 that were deployed in November 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b581f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"+TYPE: \\\"sipecam:{FILE_TYPE}\\\" AND +(sipecam:DateDeployment: [{MIN_DATE} TO {MAX_DATE}]) AND +(sipecam:CumulusName:92)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2a36e",
   "metadata": {},
   "source": [
    "### Call Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c01dc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.get(\"ALFRESCO_API_ENDPOINT\") is None or CONFIG.get(\"ALFRESCO_API_KEY\") is None:\n",
    "    raise Exception(\"Keys not detected\")\n",
    "else:    \n",
    "    skipcount = 0\n",
    "    end_of_pagination = False\n",
    "    saved_files = []\n",
    "    \n",
    "    # A cumulus can have more than the MAX_ITEMS allowed in the pagination, so\n",
    "    # a loop is necessary.\n",
    "    while not end_of_pagination:\n",
    "        \n",
    "        session = login_alfresco(CONFIG.get(\"ALFRESCO_API_KEY\"))\n",
    "\n",
    "        req = session.post(CONFIG.get(\"ALFRESCO_API_ENDPOINT\"),\n",
    "                           data=json.dumps({\n",
    "                               \"query\": {\n",
    "                                   \"query\": query,\n",
    "                                   \"language\": \"afts\"\n",
    "                               },\n",
    "                               \"include\": [\"properties\", \"path\"],\n",
    "                               \"sort\": [{\"type\": \"FIELD\", \"field\": \"cm:name\", \"ascending\": \"false\"}],\n",
    "                               \"paging\": {\n",
    "                                   \"maxItems\": MAX_ITEMS,\n",
    "                                   \"skipCount\": skipcount\n",
    "                               }\n",
    "                           })\n",
    "                        )\n",
    "\n",
    "        result = req.json()\n",
    "        \n",
    "        try:\n",
    "            if not result[\"list\"][\"pagination\"][\"hasMoreItems\"]:\n",
    "                end_of_pagination = True\n",
    "        except:\n",
    "            if result[\"error\"]:\n",
    "                raise Exception(result[\"error\"])\n",
    "\n",
    "        file_name = f\"{OUTPUT_PATH}/search_result_{FILE_TYPE}_{CUMULUS}_{skipcount}.json\"\n",
    "        # Every pagination will be saved as a json\n",
    "        save_json(result, file_name)\n",
    "        saved_files.append(file_name)\n",
    "        skipcount += MAX_ITEMS\n",
    "        \n",
    "    path_list = []\n",
    "\n",
    "    # Afterward we only want to extract the path in order to find easily the files\n",
    "    for json_file in saved_files:\n",
    "        result = read_json(json_file)\n",
    "\n",
    "        totalItems = result[\"list\"][\"pagination\"][\"totalItems\"]\n",
    "        entries_list = (result[\"list\"][\"entries\"])\n",
    "\n",
    "        for entry in entries_list:\n",
    "            complete_path = f'{entry[\"entry\"][\"path\"][\"name\"]}/{entry[\"entry\"][\"name\"]}'\n",
    "\n",
    "            # This replacement name will depend on your mounting path.\n",
    "            complete_path = complete_path.replace(\"/Company Home/Sites/sipecam/documentLibrary/\", f\"data/\")\n",
    "            path_list.append([complete_path])\n",
    "\n",
    "    path_csv = f\"{OUTPUT_PATH}/{FILE_TYPE}_path_{CUMULUS}.csv\"\n",
    "    save_list_as_csv(path_csv, [\"item\"], path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8190b",
   "metadata": {},
   "source": [
    "## Access to one object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f777ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e42dc",
   "metadata": {},
   "source": [
    "## See if the video exists on the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97694367",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = s3_client.list_objects_v2(Bucket=BUCKET_NAME, Prefix=path)\n",
    "\n",
    "if 'Contents' in result:\n",
    "    print(\"Key exists in the bucket.\")\n",
    "    obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=path)\n",
    "    object_stream = obj['Body'].read()\n",
    "else:\n",
    "    print(\"Key doesn't exist in the bucket.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
